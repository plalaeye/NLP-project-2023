{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZCcOTMfohZn",
        "outputId": "12db7411-2363-4b20-ed54-54543341af4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.2)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e99c92989f3ba450fa46d61a03390fb4b324bd8143e4be30b89004955a426a4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, multidict, lightning-utilities, frozenlist, docker-pycreds, async-timeout, yarl, gitdb, aiosignal, GitPython, aiohttp, wandb, torchmetrics, pytorch-lightning\n",
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 docker-pycreds-0.4.0 frozenlist-1.3.3 gitdb-4.0.10 lightning-utilities-0.8.0 multidict-6.0.4 pathtools-0.1.2 pytorch-lightning-2.0.2 sentry-sdk-1.21.1 setproctitle-1.3.2 smmap-5.0.0 torchmetrics-0.11.4 wandb-0.15.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j6TVUs1ozVb",
        "outputId": "5ecf0ee9-9551-48c6-dd57-4690cf52cf55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-4.0.0-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (1.26.15)\n",
            "Installing collected packages: pythainlp\n",
            "Successfully installed pythainlp-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k90VKJHloPGo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aLJjOakWoPGr"
      },
      "outputs": [],
      "source": [
        "data_path = 'data/'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L6bQahPoPGr",
        "outputId": "859aa83c-153d-4cb6-86cc-a69a40b164f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahatsarin07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JBNrAZloPGs"
      },
      "source": [
        "## Word Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fyQGVHGCoPGt"
      },
      "outputs": [],
      "source": [
        "from pythainlp import word_tokenize\n",
        "from torchtext import vocab\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f_XnEgJLoPGt"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "val = pd.read_csv(data_path + 'val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZYpVkwwyBZlk"
      },
      "outputs": [],
      "source": [
        "train_tokens = train.text.apply(word_tokenize)\n",
        "val_tokens = val.text.apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TlLK2pRZ5yaA"
      },
      "outputs": [],
      "source": [
        "def gen_len_mask(tokens, max_len):\n",
        "  mask = []\n",
        "  for sent in tokens:\n",
        "    mask.append(len(sent) < max_len)\n",
        "  return pd.Series(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YZq_4D9O6JhN"
      },
      "outputs": [],
      "source": [
        "# remove sentences that longer than 300 tokens\n",
        "train_mask = gen_len_mask(train_tokens, 300)\n",
        "train_tokens = train_tokens[train_mask]\n",
        "train_labels = train.label[train_mask].to_numpy()\n",
        "\n",
        "val_mask = gen_len_mask(val_tokens, 300)\n",
        "val_tokens = val_tokens[val_mask]\n",
        "val_labels = val.label[val_mask].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMUHiKDSoPGu",
        "outputId": "588b3ffd-6e74-42ac-9036-cc61e6e086d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "counter = Counter(train_tokens.sum())\n",
        "v1 = vocab.vocab(counter, specials=[\"</s>\", \"<unk>\",])\n",
        "v1.set_default_index(1)\n",
        "print(v1[\"<unk>\"]) #prints 0\n",
        "print(v1['out of vocab']) #prints 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk8VbCXzoPGu",
        "outputId": "ba76877a-8c68-4f10-95cc-2467498c189c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocal size is 20589\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(v1)\n",
        "print(f\"vocal size is {vocab_size}\")\n",
        "text_pipeline = lambda sent: v1.lookup_indices(sent) # add </s> to the end of each sentence\n",
        "text_decoding = lambda encoded: \"\".join(v1.lookup_tokens(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-r76Hd_oPGu",
        "outputId": "b7d82312-a8ea-496f-8cb5-c88fa50807be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original: ลงมาเป็นเสียงสามัญ ม้าอือ อย่างนี้ก็แย่ซิครับ คือเปลี่ยนทั้งพยัญชนะ เปลี่ยนทั้งสระเปลี่ยนทั้งวรรณยุกต์ด้วย หัวผมไม่ใช่คอมพิวเตอร์ จะได้แปลคำเหล่านี้มาเป็นคำไทยได้ทันเพราะฉะนั้น เมื่อพูดถึง ม้าอือ หม่าย ผมก็แปลไม่ออก\n",
            "encoded: [226, 9, 227, 228, 4, 229, 230, 4, 231, 63, 232, 233, 234, 4, 16, 235, 236, 237, 4, 235, 236, 238, 235, 236, 239, 184, 4, 240, 62, 35, 241, 242, 4, 6, 117, 66, 243, 244, 54, 9, 243, 72, 117, 224, 245, 4, 124, 246, 4, 229, 230, 4, 247, 248, 63, 66, 35, 179]\n",
            "decoded: ลงมาเป็นเสียงสามัญ ม้าอือ อย่างนี้ก็แย่ซิครับ คือเปลี่ยนทั้งพยัญชนะ เปลี่ยนทั้งสระเปลี่ยนทั้งวรรณยุกต์ด้วย หัวผมไม่ใช่คอมพิวเตอร์ จะได้แปลคำเหล่านี้มาเป็นคำไทยได้ทันเพราะฉะนั้น เมื่อพูดถึง ม้าอือ หม่าย ผมก็แปลไม่ออก\n"
          ]
        }
      ],
      "source": [
        "encoded_sent = text_pipeline(train_tokens[10])\n",
        "print(\"original:\", \"\".join(train_tokens[10]))\n",
        "print(\"encoded:\", encoded_sent)\n",
        "print(\"decoded:\", text_decoding(encoded_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxrfx23WoPGv"
      },
      "source": [
        "### Prepare Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ul0bWY3ZoPGv"
      },
      "outputs": [],
      "source": [
        "max_train_len = len(max(train_tokens, key=len))\n",
        "max_val_len = len(max(val_tokens, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idY4-adDoPGv",
        "outputId": "b9cd177e-9e6a-4045-b248-1abf7f4eb2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max train length: 285\n",
            "Max val length: 285\n"
          ]
        }
      ],
      "source": [
        "print(\"Max train length:\", max_train_len)\n",
        "print(\"Max val length:\", max_val_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jq1kNbjfkx-i"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "x_train = [torch.LongTensor(sentence) for sentence in train_tokens.apply(text_pipeline)]\n",
        "x_val = [torch.LongTensor(sentence) for sentence in val_tokens.apply(text_pipeline)] \n",
        "\n",
        "x_train = pad_sequence(x_train, batch_first=True)\n",
        "x_val = pad_sequence(x_val, batch_first=True)\n",
        "\n",
        "# Pad the sequence length of x_test to be maxlen \n",
        "remaining_len = x_train.size(1) - x_val.size(1)\n",
        "remaining_mat = torch.zeros((x_val.size(0), remaining_len), dtype=torch.long) \n",
        "x_val = torch.cat((x_val, remaining_mat), dim=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "X-iTzF4A_YUq"
      },
      "outputs": [],
      "source": [
        "impolite_train = x_train[train_labels == 0]\n",
        "polite_train = x_train[train_labels == 1]\n",
        "\n",
        "impolite_val = x_val[val_labels == 0]\n",
        "polite_val = x_val[val_labels == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zGD7iFBooPGw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PolitenessDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.encoded = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded[idx], self.labels[idx]\n",
        "\n",
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, *datasets):\n",
        "        self.datasets = datasets\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return tuple(d[i] for d in self.datasets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(d) for d in self.datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sD58cJpboPGw"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class PolitenessDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "      pass\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_loader = DataLoader(ConcatDataset(\n",
        "                          PolitenessDataset(impolite_train, torch.zeros(impolite_train.shape[0])),\n",
        "                          PolitenessDataset(polite_train, torch.ones(polite_train.shape[0]))\n",
        "                      ),\n",
        "                      batch_size = self.batch_size, \n",
        "                      shuffle = True, \n",
        "                      num_workers = self.num_workers)\n",
        "\n",
        "      return train_loader\n",
        "  \n",
        "  def val_dataloader(self):\n",
        "      val_loader = DataLoader(ConcatDataset(\n",
        "                          PolitenessDataset(impolite_val, torch.zeros(impolite_val.shape[0])),\n",
        "                          PolitenessDataset(polite_val, torch.ones(impolite_val.shape[0]))\n",
        "                      ),\n",
        "                      batch_size = self.batch_size, \n",
        "                      shuffle = False, \n",
        "                      num_workers = self.num_workers)\n",
        "      return val_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Sqi__U2ooPGy"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "data_module = PolitenessDataModule(batch_size=batch_size, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wqENvEzqvaT",
        "outputId": "692b14d0-1faf-4459-f091-d8e600c5c224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[tensor([[ 1769,  5522,   211,  ...,     0,     0,     0],\n",
              "          [   54,  4577,  4578,  ...,     0,     0,     0],\n",
              "          [   77,  1503,   510,  ...,     0,     0,     0],\n",
              "          ...,\n",
              "          [  360,   361,   211,  ...,     0,     0,     0],\n",
              "          [10616,  1840,   530,  ...,     0,     0,     0],\n",
              "          [ 2226,   308,   160,  ...,     0,     0,     0]]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])],\n",
              " [tensor([[   62, 11326,  9274,  ...,     0,     0,     0],\n",
              "          [  397,    29,    37,  ...,     0,     0,     0],\n",
              "          [  805,   611,   403,  ...,     0,     0,     0],\n",
              "          ...,\n",
              "          [   59,    62,  2354,  ...,     0,     0,     0],\n",
              "          [  117,  4419,   153,  ...,     0,     0,     0],\n",
              "          [  882,   163,  1342,  ...,     0,     0,     0]]),\n",
              "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])]]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(data_module.train_dataloader()))\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3LW2BZEoPGw"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7j4EAOX4oPGw"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from pytorch_lightning import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8E-ricTInn7S"
      },
      "outputs": [],
      "source": [
        "Ty = max_train_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zIiV-BYOoPGx"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embeding_size, hidden_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding_size = embeding_size\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "        self.gru = nn.GRU(self.embedding_size, hidden_dim, n_layers, batch_first=True)\n",
        "       \n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, hidden = self.gru(embedded)\n",
        "        return hidden[-1]\n",
        "    \n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, input_dim, hidden_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.gru_cell = nn.GRUCell(input_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, self.vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x, hx):\n",
        "        hx = self.gru_cell(x, hx)\n",
        "        logit = self.fc(hx)\n",
        "        return logit, hx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kuRfam1PoPGx"
      },
      "outputs": [],
      "source": [
        "class MultiDecoderModel(pl.LightningModule):\n",
        "    def __init__(self, criterion1, criterion2, learning_rate):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = 64\n",
        "        self.hidden_dim = 64\n",
        "        self.vocab_size = vocab_size\n",
        "        self.encoder = Encoder(self.vocab_size, self.embedding_dim, self.hidden_dim)\n",
        "        self.decoders = nn.ModuleList([Decoder(self.vocab_size, self.hidden_dim, self.hidden_dim) for i in range(2)])\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, 32),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.decoder_criterion = criterion1\n",
        "        self.cls_criterion = criterion2\n",
        "\n",
        "    def forward(self, src, label_idx):\n",
        "        context = self.encoder(src)\n",
        "        decoder_h = torch.randn(src.shape[0], self.hidden_dim).to(self.decoders[label_idx].gru_cell.weight_ih.device)\n",
        "\n",
        "        prediction = torch.zeros((src.shape[0], Ty, self.vocab_size)).to(self.decoders[label_idx].gru_cell.weight_ih.device)\n",
        "        \n",
        "        # Iterate until max_output_length\n",
        "        for t in range(Ty):\n",
        "            out, decoder_h = self.decoders[label_idx](context, decoder_h)\n",
        "\n",
        "            prediction[:, t] = out\n",
        "        return prediction, context\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        impolite_inputs, impolite_labels = batch[0]\n",
        "        polite_inputs, polite_labels = batch[1]\n",
        "  \n",
        "        prediction_0, context_0 = self(impolite_inputs, 0)\n",
        "        prediction_1, context_1 = self(polite_inputs, 1)\n",
        "\n",
        "        contexts = torch.concat([context_0, context_1])\n",
        "        labels = torch.concat([impolite_labels, polite_labels])\n",
        "\n",
        "        # classification from context vector\n",
        "        y_pred = self.classifier(contexts)\n",
        "        y_pred = y_pred.squeeze()\n",
        "        avr_loss1 = self.cls_criterion(y_pred, labels)\n",
        "        avr_loss2 = torch.sum(y_pred * torch.log2(y_pred) + (1 - y_pred) * torch.log2(1 - y_pred)) # negative of entropy\n",
        "\n",
        "        # calculate loss of each decoder networks\n",
        "        gen0_loss = self.decoder_criterion(prediction_0.reshape(-1, vocab_size), impolite_inputs.reshape(-1))\n",
        "        gen1_loss = self.decoder_criterion(prediction_1.reshape(-1, vocab_size), polite_inputs.reshape(-1))\n",
        "    \n",
        "        # total lostt\n",
        "        loss = gen0_loss + gen1_loss + avr_loss1 + avr_loss2\n",
        "\n",
        "        self.log(\"training_loss\", loss)\n",
        "        self.log(\"training_gen_loss\", gen1_loss + gen0_loss)\n",
        "        self.log(\"training_adversarial_loss_1\", avr_loss1)\n",
        "        self.log(\"training_adversarial_loss_2\", avr_loss2)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        impolite_inputs, impolite_labels = batch[0]\n",
        "        polite_inputs, polite_labels = batch[1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction_0, context_0 = self(impolite_inputs, 0)\n",
        "            prediction_1, context_1 = self(polite_inputs, 1)\n",
        "\n",
        "            contexts = torch.concat([context_0, context_1])\n",
        "            labels = torch.concat([impolite_labels, polite_labels])\n",
        "\n",
        "            # classification from context vector\n",
        "            y_pred = self.classifier(contexts)\n",
        "            y_pred = y_pred.squeeze()\n",
        "            avr_loss1 = self.cls_criterion(y_pred, labels)\n",
        "            avr_loss2 = torch.sum(y_pred * torch.log2(y_pred) + (1 - y_pred) * torch.log2(1 - y_pred)) # negative of entropy\n",
        "\n",
        "            # calculate loss of each decoder networks\n",
        "            gen0_loss = self.decoder_criterion(prediction_0.reshape(-1, vocab_size), impolite_inputs.reshape(-1))\n",
        "            gen1_loss = self.decoder_criterion(prediction_1.reshape(-1, vocab_size), polite_inputs.reshape(-1))\n",
        "        \n",
        "            # total lostt\n",
        "            loss = gen0_loss + gen1_loss + avr_loss1 + avr_loss2\n",
        "\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_gen_loss\", gen1_loss + gen0_loss)\n",
        "        self.log(\"val_adversarial_loss\", avr_loss1)\n",
        "        self.log(\"val_adversarial_loss\", avr_loss2)\n",
        "        return loss\n",
        "    \n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        inputs, labels = batch\n",
        "        with torch.no_grad():\n",
        "          prediction, _ = self(inputs, 0)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(\"\".join(v1.lookup_tokens(pred.cpu().numpy())))\n",
        "        return prediction\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adadelta(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rMW6E5RZoPGx"
      },
      "outputs": [],
      "source": [
        "lr = 3e-4\n",
        "criterion1 = nn.CrossEntropyLoss(reduction='sum')\n",
        "criterion2 = nn.BCELoss(reduction='sum')\n",
        "\n",
        "model = MultiDecoderModel(criterion1, criterion2, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "jxfaaUY2oPGy",
        "outputId": "7c11b5f2-3b6b-49fa-a28b-4ff0161ee19f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahatsarin07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230430_112551-ct2qbigq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sahatsarin07/final_project/runs/ct2qbigq' target=\"_blank\">stellar-pond-17</a></strong> to <a href='https://wandb.ai/sahatsarin07/final_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sahatsarin07/final_project' target=\"_blank\">https://wandb.ai/sahatsarin07/final_project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sahatsarin07/final_project/runs/ct2qbigq' target=\"_blank\">https://wandb.ai/sahatsarin07/final_project/runs/ct2qbigq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"final_project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo_dLvkyoPGy",
        "outputId": "6291ef50-c6d1-4610-9f2a-727c4e4af805"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    default_root_dir='checkpoints/multi_decoder/',\n",
        "    max_epochs=15,\n",
        "    devices=1,\n",
        "    logger=wandb_logger,\n",
        "    callbacks=[pl.callbacks.ModelCheckpoint(filename='best',monitor='val_gen_loss')]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "1ec67328ce734b4cb08d98c5ff728a3e",
            "e7baa206529741be9506611e61c3134a",
            "9e394140bf7b43fdadd2f6135759af0d",
            "44a209753da64f50b8456c5414a56c82",
            "3960c01c07d648c5be9e1a7d0499d685",
            "f6691e336b034ca69ab7b5173ad45927",
            "2619d4c6e2124d1580b2044037ea3790",
            "aca7480a43ac4c5bb18a5c769beaa618",
            "5e0f8bed90044510b4d70558c70f1db0",
            "c317c49b0d0245729dbe393987a85c5a",
            "daa1f9b03ec343bca258cf8b4b24ceaa",
            "7efd8c16a437466392d5c80898dc453d",
            "3b53be61fecf450b9c2e24279cd374fa",
            "1b2b8900c0db4fbaa7c08ba3b9f57106",
            "8877bef6d9254e77ba10fd12abfa9db3",
            "b17ca1d7f09d4b098f4fb4799e6c25ef",
            "503a1754335041b0990362a8ea157211",
            "507c8dc5d13e44a9a85269b7cee93f0b",
            "180ddfc76e104625b17af78d35d84e33",
            "142dd53a5cab403f8525f14bf9369fba",
            "36733d5f22c74f79af3700aa2da9bcb0",
            "ffd6d6b4f2994f26b483abeb742c87ff"
          ]
        },
        "id": "h-X5v0UNoPGy",
        "outputId": "ba7411d9-8585-4c4f-cbb5-e9b7a06e9e97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type             | Params\n",
            "-------------------------------------------------------\n",
            "0 | encoder           | Encoder          | 1.3 M \n",
            "1 | decoders          | ModuleList       | 2.7 M \n",
            "2 | classifier        | Sequential       | 2.1 K \n",
            "3 | decoder_criterion | CrossEntropyLoss | 0     \n",
            "4 | cls_criterion     | BCELoss          | 0     \n",
            "-------------------------------------------------------\n",
            "4.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.1 M     Total params\n",
            "16.285    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ec67328ce734b4cb08d98c5ff728a3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7efd8c16a437466392d5c80898dc453d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Zw3UGJoPGy"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL8qS-1XKczs"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g87gAuqXKcAG"
      },
      "outputs": [],
      "source": [
        "EXAMPLES = ['แอคกูปะ','ตังออกวันไหน','ทำไมอินนิสฟรีที่สั่งในจมก.ยังไม่เริ่มจัดส่งอีกกกกก นานแล้วนะว้อยยย','นี่ถ้าเป็นนู๋เตรียมบัตรแล้วน่ะเนี้ย','ได้น้องแล้วค่ะ ตัวแน่นมากกกกก😣💓💓']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXmLJD2xKhzV"
      },
      "outputs": [],
      "source": [
        "predict_data = []\n",
        "for line in EXAMPLES:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    predict_data.append(torch.tensor(v1(line)))\n",
        "\n",
        "print(len(predict_data))\n",
        "\n",
        "\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n",
        "predict_dataset = PolitenessDataset(predict_data, torch.zeros(len(predict_data)))\n",
        "predict_loader = DataLoader(predict_dataset,\n",
        "                            batch_size = 1,\n",
        "                            shuffle = False,\n",
        "                            num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDxWZGF0MQ1q"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcWArsikMUWn"
      },
      "outputs": [],
      "source": [
        "output = trainer.predict(model, predict_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "142dd53a5cab403f8525f14bf9369fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "180ddfc76e104625b17af78d35d84e33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2b8900c0db4fbaa7c08ba3b9f57106": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_180ddfc76e104625b17af78d35d84e33",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_142dd53a5cab403f8525f14bf9369fba",
            "value": 40
          }
        },
        "1ec67328ce734b4cb08d98c5ff728a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7baa206529741be9506611e61c3134a",
              "IPY_MODEL_9e394140bf7b43fdadd2f6135759af0d",
              "IPY_MODEL_44a209753da64f50b8456c5414a56c82"
            ],
            "layout": "IPY_MODEL_3960c01c07d648c5be9e1a7d0499d685"
          }
        },
        "2619d4c6e2124d1580b2044037ea3790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36733d5f22c74f79af3700aa2da9bcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3960c01c07d648c5be9e1a7d0499d685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "3b53be61fecf450b9c2e24279cd374fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_503a1754335041b0990362a8ea157211",
            "placeholder": "​",
            "style": "IPY_MODEL_507c8dc5d13e44a9a85269b7cee93f0b",
            "value": "Epoch 0:  53%"
          }
        },
        "44a209753da64f50b8456c5414a56c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c317c49b0d0245729dbe393987a85c5a",
            "placeholder": "​",
            "style": "IPY_MODEL_daa1f9b03ec343bca258cf8b4b24ceaa",
            "value": " 2/2 [00:04&lt;00:00,  2.28s/it]"
          }
        },
        "503a1754335041b0990362a8ea157211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "507c8dc5d13e44a9a85269b7cee93f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e0f8bed90044510b4d70558c70f1db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7efd8c16a437466392d5c80898dc453d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b53be61fecf450b9c2e24279cd374fa",
              "IPY_MODEL_1b2b8900c0db4fbaa7c08ba3b9f57106",
              "IPY_MODEL_8877bef6d9254e77ba10fd12abfa9db3"
            ],
            "layout": "IPY_MODEL_b17ca1d7f09d4b098f4fb4799e6c25ef"
          }
        },
        "8877bef6d9254e77ba10fd12abfa9db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36733d5f22c74f79af3700aa2da9bcb0",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd6d6b4f2994f26b483abeb742c87ff",
            "value": " 40/75 [06:27&lt;05:39,  9.70s/it, v_num=bigq]"
          }
        },
        "9e394140bf7b43fdadd2f6135759af0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca7480a43ac4c5bb18a5c769beaa618",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e0f8bed90044510b4d70558c70f1db0",
            "value": 2
          }
        },
        "aca7480a43ac4c5bb18a5c769beaa618": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17ca1d7f09d4b098f4fb4799e6c25ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c317c49b0d0245729dbe393987a85c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa1f9b03ec343bca258cf8b4b24ceaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7baa206529741be9506611e61c3134a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6691e336b034ca69ab7b5173ad45927",
            "placeholder": "​",
            "style": "IPY_MODEL_2619d4c6e2124d1580b2044037ea3790",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "f6691e336b034ca69ab7b5173ad45927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd6d6b4f2994f26b483abeb742c87ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
